
import AuthorDetails from '@site/src/components/AuthorDetails';

## 一起ß

#### 改编自 https://github.com/insop 提供的文档

### 先决条件

- 为了非缓存示例，请设置 `api_key` 和 `api_base`。
在您的开发环境的 `.env` 文件中设置如下：

```
TOGETHER_API_BASE = ...
TOGETHER_API_KEY = ...
```

这将在 Together 客户端中被检索为：
```python
self.api_base = os.getenv("TOGETHER_API_BASE")
self.token = os.getenv("TOGETHER_API_KEY")
```

### 设置 Together 客户端

构造函数初始化 `HFModel` 基类以支持提示模型的处理。这需要以下参数：

**参数:**
- `model` (_str_): 托管在 Together 端点上的模型 ID。
- `**kwargs`: 配置 Together 客户端的额外关键字参数。

Together 构造函数示例：

```python
class Together(HFModel):
    def __init__(self, model, **kwargs):
```

### 内部机制

#### `_generate(self, prompt, use_chat_api=False, **kwargs):`

**参数:**
- `prompt` (_str_): 发送到 Together 的提示。
- `use_chat_api` (_bool_): 是否使用 Together 聊天模型端点的标志。默认为 False。
- `**kwargs`: 用于完成请求的额外关键字参数。

**返回:**
- `dict`: 包含 `prompt` 和响应 `choices` 列表的字典。

在内部，该方法处理准备请求提示和相应有效载荷以获取响应的具体细节。

Together 令牌设置在请求标头中，以确保授权发送请求到端点。

如果设置了 `use_chat_api`，该方法将设置 Together url 聊天端点和聊天模型的提示模板。然后检索生成的 JSON 响应，并通过检索响应的 `message` : `content` 设置 `completions` 列表。

如果未设置 `use_chat_api`，该方法将使用默认的 Together url 端点。类似地检索生成的 JSON 响应，但通过将响应的 `text` 设置为完成来设置 `completions` 列表。

最后，在处理请求和响应后，该方法使用两个键构造响应字典：原始请求 `prompt` 和 `choices`，一个表示生成的 `completions` 的字典列表，其中键 `text` 包含响应生成的文本。

### 使用 Together 客户端

```python
together = dspy.Together(model="mistralai/Mistral-7B-v0.1")
```

### 通过 Together 客户端发送请求

1) _**推荐**_ 使用 `dspy.configure` 配置默认 LM。

这允许您在 DSPy 中定义程序，并简单地在输入字段上调用模块，让 DSPy 在内部调用配置的 LM 上的提示。

```python
dspy.configure(lm=together)

#示例 DSPy CoT QA 程序
qa = dspy.ChainOfThought('question -> answer')

response = qa(question="巴黎的首都是什么？") #提示到 together
print(response.answer)
```

2) 直接使用客户端生成响应。

```python
response = together(prompt='巴黎的首都是什么？')
print(response)
```
***

<AuthorDetails name="Arnav Singhvi"/>