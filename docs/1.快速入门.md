



## DSPy：编程基础模型，而非提示

**[Oct'23] [DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines](https://arxiv.org/abs/2310.03714)**     
[Jan'24] [In-Context Learning for Extreme Multi-Label Classification](https://arxiv.org/abs/2401.12178)       
[Dec'23] [DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines](https://arxiv.org/abs/2312.13382)   
[Dec'22] [Demonstrate-Search-Predict: Composing Retrieval & Language Models for Knowledge-Intensive NLP](https://arxiv.org/abs/2212.14024.pdf)


**入门指南：** &nbsp; [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/intro.ipynb)

**文档：** [DSPy 文档](https://dspy-docs.vercel.app/)

----

**DSPy 是一个用于算法优化 LM 提示和权重的框架**，特别是当 LM 在管道中使用一次或多次时。要在不使用 DSPy 的情况下使用 LM 构建复杂系统，通常需要：(1) 将问题分解为步骤，(2) 良好提示您的 LM，直到每个步骤在隔离状态下运行良好，(3) 调整步骤以使其共同运行良好，(4) 生成合成示例来调整每个步骤，并且 (5) 使用这些示例微调较小的 LM 以降低成本。目前，这很困难且混乱：每次更改管道、LM 或数据时，所有提示（或微调步骤）可能都需要更改。

为了使这更加系统化和更加强大，**DSPy** 做了两件事。首先，它将程序的流程（`模块`）与每个步骤的参数（LM 提示和权重）分开。其次，**DSPy** 引入了新的 `优化器`，这些是 LM 驱动的算法，可以调整您的 LM 调用的提示和/或权重，给定您想要最大化的 `度量`。

**DSPy** 可以经常教授强大的模型，如 `GPT-3.5` 或 `GPT-4`，以及本地模型，如 `T5-base` 或 `Llama2-13b`，使其在任务中更加可靠，即具有更高的质量和/或避免特定的失败模式。**DSPy** 优化器将将相同程序编译成不同的指令、少量提示和/或权重更新（微调）用于每个 LM。这是一个新的范式，其中 LM 及其提示淡化为可以从数据中学习的更大系统的可优化部分。**tldr;** 较少提示，更高分数，以及更系统化地解决 LM 难题的方法。


### 目录

如果您需要帮助思考您的任务，我们最近为社区创建了一个 [Discord 服务器](https://discord.gg/VzS6RHHK6F)。

1. **[安装](#1-installation)**
1. **[教程与文档](#2-documentation)**
1. **[框架语法](#3-syntax-youre-in-charge-of-the-workflowits-free-form-python-code)**
1. **[编译：两个强大的概念](#4-two-powerful-concepts-signatures--teleprompters)**
1. **[Pydantic 类型](#5-pydantic-types)** 
1. **[常见问题：DSPy 是否适合我？](#6-faq-is-dspy-right-for-me)**



### 类比神经网络

在构建神经网络时，我们不会手动编写对手动调整的浮点数列表的 _for-循环_。相反，您可能会使用类似 [PyTorch](https://pytorch.org/) 的框架来组合声明性层（例如 `Convolution` 或 `Dropout`），然后使用优化器（例如 SGD 或 Adam）来学习网络的参数。

同样，**DSPy** 为您提供了正确的通用模块（例如 `ChainOfThought`、`ReAct` 等），这些模块取代了基于字符串的提示技巧。为了替代提示的黑客技巧和一次性合成数据生成器，**DSPy** 还为您提供了通用优化器（`BootstrapFewShotWithRandomSearch` 或 [`BayesianSignatureOptimizer`](https://github.com/stanfordnlp/dspy/blob/main/dspy/teleprompt/signature_opt_bayesian.py)），这些算法会更新程序中的参数。每当您修改代码、数据、断言或指标时，您可以再次 _编译_ 您的程序，**DSPy** 将创建适应您更改的新有效提示。

### 迷你常见问题解答

**DSPy 优化器调整什么？** 每个优化器都不同，但它们都旨在通过更新提示或 LM 权重来最大化程序中的指标。当前的 DSPy `优化器` 可以检查您的数据，模拟通过程序的跟踪以生成每个步骤的好/坏示例，根据过去的结果提出或完善每个步骤的指令，对 LM 在自动生成的示例上进行微调，或结合其中几种方法来提高质量或降低成本。我们很乐意合并探索更丰富空间的新优化器：您目前为提示工程、"合成数据"生成或自我改进所经历的大部分手动步骤可能可以泛化为一个在任意 LM 程序上操作的 DSPy 优化器。

**我应该如何为我的任务使用 DSPy？** 使用 DSPy 是一个迭代的过程。您首先定义您的任务和要最大化的指标，并准备一些示例输入 —— 通常没有标签（或者仅在最终输出需要标签时有标签，如果您的指标需要）。然后，通过选择内置层（`模块`）来构建您的管道，为每个层指定一个 `signature`（输入/输出规范），然后在您的 Python 代码中自由调用您的模块。最后，您可以使用 DSPy `优化器` 来编译您的代码，生成高质量指令、自动少样本示例，或更新 LM 权重。

**如果我有更好的提示或合成数据生成想法怎么办？** 太好了。我们鼓励您思考它是最好表达为一个模块还是一个优化器，我们很乐意将其合并到 DSPy 中，以便每个人都可以使用。DSPy 不是一个完成的项目；它是一个持续努力，旨在创建结构（模块和优化器）来取代繁琐的提示和管道工程技巧。
**DSPy** 代表什么？这是一个很长的故事，但现在的反向缩略语是 **D**eclarative **S**elf-improving Language **P**rograms，以 Python 风格编写。

## 1) 安装

你只需要：

```bash
pip install dspy-ai
```

要安装最新版本的 `main` 分支：

```bash
pip install git+https://github.com/stanfordnlp/dspy.git
````

或者在 Google Colab 中打开我们的介绍笔记本：[<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/intro.ipynb)

默认情况下，DSPy 会从 pip 安装最新的 `openai`。然而，如果你在 OpenAI 更改他们的 API 之前安装了旧版本 `openai~=0.28.1`，该库也会正常使用。两者都受支持。

对于可选的（按字母顺序排序）[Chromadb](https://github.com/chroma-core/chroma)、[Qdrant](https://github.com/qdrant/qdrant)、[Marqo](https://github.com/marqo-ai/marqo)、Pinecone、[Snowflake](https://github.com/snowflakedb/snowpark-python)、[Weaviate](https://github.com/weaviate/weaviate) 或 [Milvus](https://github.com/milvus-io/milvus) 检索集成，包括以下额外内容：

```
pip install dspy-ai[chromadb]  # 或 [qdrant] 或 [marqo] 或 [mongodb] 或 [pinecone] 或 [snowflake] 或 [weaviate] 或 [milvus]
```

## 2) 文档

DSPy 文档分为 **教程**（逐步演示在 DSPy 中解决任务的过程）、**指南**（如何使用 API 的特定部分）和 **示例**（说明用法的独立程序）。

### A) 教程

| **级别** |  **教程** |  **在 Colab 中运行** |  **描述** |
| --- | -------------  |  -------------  |  -------------  | 
| 初学者 |  [**入门指南**](intro.ipynb) | [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/intro.ipynb)  | 介绍了 DSPy 中的基本构建模块。解决了使用 HotPotQA 进行复杂问题回答的任务。 |
| 初学者 | [**最小工作示例**](https://dspy-docs.vercel.app/docs/quick-start/minimal-example) | N/A | 在 DSPy 中构建和优化一个非常简单的思维链程序，用于数学问题回答。非常简短。 |
| 初学者 | [**为复杂任务编译**](examples/nli/scone/scone.ipynb) | N/A | 教会语言模型推理逻辑陈述和否定。使用 GPT-4 为 GPT-3.5 启动少量 CoT 演示。在 [ScoNe](https://arxiv.org/abs/2305.19426) 上取得了最新成果。由 [Chris Potts](https://twitter.com/ChrisGPotts/status/1740033519446057077) 贡献。 |
| 初学者 | [**本地模型和自定义数据集**](skycamp2023.ipynb) | [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/skycamp2023.ipynb) | 结合展示了两个不同的内容：如何使用本地模型（特别是Llama-2-13B），以及如何使用自己的数据示例进行训练和开发。
| 中级 | [**DSPy 论文**](https://arxiv.org/abs/2310.03714) | N/A | DSPy 论文的第3、5、6和7节可作为教程。其中包括了代码片段解释、结果以及对抽象和API的讨论。
| 中级 | [**DSPy 断言**](https://arxiv.org/abs/2312.13382) | [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/examples/longformqa/longformqa_assertions.ipynb) | 展示了应用 DSPy 断言的示例，用于生成对问题的长篇回答，并附带引用。在零-shot和编译设置中进行了比较评估。
| 中级 | [**针对复杂程序的微调**](https://twitter.com/lateinteraction/status/1712135660797317577) | [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/examples/qa/hotpot/multihop_finetune.ipynb) | 教授本地 T5 模型（770M）在 HotPotQA 上表现出色。仅使用了200个标记答案。没有手写提示，没有调用 OpenAI，也没有用于检索或推理的标签。
| 高级 | [**信息提取**](https://twitter.com/KarelDoostrlnck/status/1724991014207930696) | [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/drive/1CpsOiLiLYKeGrhmq579_FmtGsD5uZ3Qe) | 处理从长文章（生物医学研究论文）中提取信息的挑战。结合上下文学习和检索，以在 BioDEX 上取得 SOTA。由 [Karel D’Oosterlinck](https://twitter.com/KarelDoostrlnck/status/1724991014207930696) 贡献。  |

**其他人们发现有用的资源**:

- [ScaleByTheBay 2023 年 DSPy 演讲](https://www.youtube.com/watch?v=Dt3H2ninoeY)。
- [与 MLOps 学习者一起的 DSPy 网络研讨会](https://www.youtube.com/watch?v=im7bCLW2aM4)，包含问答环节，稍长一些。
- 社区对 DSPy 的实践概述: [Connor Shorten 解释的 DSPy！](https://www.youtube.com/watch?v=41EfOY0Ldkc), [code_your_own_ai 解释的 DSPy](https://www.youtube.com/watch?v=ycfnKPxBMck), [AI Bites 的 DSPy 速成课](https://youtu.be/5-zgASQKkKQ?si=3gnmVouT5_rpk_nu), [Unify 解释的 DSPy 论文](https://youtu.be/kFB8kFchCH4?si=FuM6L5H5lweanckz)
- 采访: [Weaviate Podcast 线下采访](https://www.youtube.com/watch?v=CDung1LnLbY)，您还可以在 YouTube 上找到其他 6-7 个不同角度/受众的远程播客。
- 使用 Arize Phoenix 进行 DSPy 的跟踪：[跟踪您的提示和 DSPy 程序步骤的教程](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/dspy_tracing_tutorial.ipynb)
- [DSPy：非同寻常的提示工程](https://jina.ai/news/dspy-not-your-average-prompt-engineering)，为何对未来的提示工程至关重要，以及为何对提示工程师来说学习它是具有挑战性的。
- 使用 Parea AI 进行 DSPy 的跟踪和优化追踪：[跟踪和评估 DSPy RAG 程序的教程](https://docs.parea.ai/tutorials/dspy-rag-trace-evaluate/tutorial)

### B) 指南

如果您是 DSPy 的新手，最好按顺序进行。之后您可能经常会参考这些指南，例如复制/粘贴片段，然后编辑为您自己的 DSPy 程序。

1. **[语言模型](https://dspy-docs.vercel.app/docs/building-blocks/language_models)**

2. **[签名](https://dspy-docs.vercel.app/docs/building-blocks/signatures)**

3. **[模块](https://dspy-docs.vercel.app/docs/building-blocks/modules)**

4. **[数据](https://dspy-docs.vercel.app/docs/building-blocks/data)**

5. **[指标](https://dspy-docs.vercel.app/docs/building-blocks/metrics)**

6. **[优化器（以前称为 Teleprompters）](https://dspy-docs.vercel.app/docs/building-blocks/optimizers)**

7. **[DSPy 断言](https://dspy-docs.vercel.app/docs/building-blocks/assertions)**

### C) 示例

DSPy 团队认为复杂性必须得到证明。我们认真对待这一点：我们从不发布复杂的教程（上述）或示例（下述），_除非我们可以凭经验证明这种复杂性通常导致了质量或成本的提高。_ 其他框架或文档很少强制执行这样的规则，但在 DSPy 示例中您可以信赖它。

`examples/` 目录和顶层目录中有许多示例。我们欢迎贡献！

您可以在 Twitter/X 上找到 [@lateinteraction](https://twitter.com/lateinteraction) 发布的其他示例。

**其他示例（不全，欢迎通过 PR 添加更多）：**

- [DSPy 优化器在各种不同任务上的基准测试，由 Michael Ryan](https://github.com/stanfordnlp/dspy/tree/main/testing/tasks)
- [Sophisticated Extreme Multi-Class Classification, IReRa，由 Karel D’Oosterlinck](https://github.com/KarelDO/xmc.dspy)
- [Haize Lab 使用 DSPy 进行红队行动](https://blog.haizelabs.com/posts/dspy/)，并查看[他们的 DSPy 代码](https://github.com/haizelabs/dspy-redteam)
- 应用 DSPy 断言
  - [带引用的长格式答案生成，由 Arnav Singhvi](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/examples/longformqa/longformqa_assertions.ipynb)
  - [为测验问题生成答案选项，由 Arnav Singhvi](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/examples/quiz/quiz_assertions.ipynb)
- [生成问答推文，作者：Arnav Singhvi](https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/examples/tweets/tweets_assertions.ipynb)
- [从 LangChain 在 DSPy 中编译 LCEL 可运行文件](https://github.com/stanfordnlp/dspy/blob/main/examples/tweets/compiling_langchain.ipynb)
- [AI 反馈，或在 DSPy 中编写基于 LM 的度量标准](https://github.com/stanfordnlp/dspy/blob/main/examples/tweets/tweet_metric.py)
- [DSPy 优化器在多种不同任务上的基准测试，作者：Michael Ryan](https://github.com/stanfordnlp/dspy/tree/main/testing/README.md)
- [由 Saiful Haq 进行编译后印度语言 NLI 的收益](https://github.com/saifulhaq95/DSPy-Indic/blob/main/indicxlni.ipynb)
- [DSPy 在 BIG-Bench 的难题上的应用，作者：Chris Levy](https://drchrislevy.github.io/posts/dspy/dspy.html)
- [使用 Ollama 与 DSPy 为 Mistral（量化）进行处理，作者：@jrknox1977](https://gist.github.com/jrknox1977/78c17e492b5a75ee5bbaf9673aee4641)
- [使用 DSPy，《古怪自动提示的不合理有效性》（论文）作者：VMware 的 Rick Battle & Teja Gollapudi](https://arxiv.org/abs/2402.10949)，以及 [TheRegister 的采访](https://www.theregister.com/2024/02/22/prompt_engineering_ai_models/)
- [通过 DSPy 和 vLLM 优化开源 LM 在文本到 SQL 的性能，作者：Juan Ovalle](https://github.com/jjovalle99/DSPy-Text2SQL)
- Typed DSPy（由 [@normal-computing](https://github.com/normal-computing) 贡献）
  - [使用 DSPy 在 HumanEval 上训练 Gpt 3.5，作者：Thomas Ahle](https://github.com/stanfordnlp/dspy/blob/main/examples/functional/functional.ipynb)
  - [使用 DSPy 构建一个国际象棋对弈代理，作者：Franck SN](https://medium.com/thoughts-on-machine-learning/building-a-chess-playing-agent-using-dspy-9b87c868f71e)


待办事项：添加多伦多大学在临床自然语言处理、Plastic Labs 在心灵理论（ToM）上的最新成果，以及 Replit 的 DSPy 管道的链接。

还有最近在 [Weaviate 的 DSPy 烹饪书](https://github.com/weaviate/recipes/tree/main/integrations/dspy) 中由 Connor Shorten 提供的酷例。[查看 YouTube 上的教程](https://www.youtube.com/watch?v=CEuUG4Umfxs)。

## 3) 语法：您负责工作流程——这是自由形式的 Python 代码！

**DSPy** 隐藏了繁琐的提示工程，但清晰地展示了您需要做出的重要决策：**[1]** 您的系统设计将是什么样子？**[2]** 您的程序行为的重要约束是什么？

您可以将系统表达为自由形式的 Python 模块。**DSPy** 将调整您的程序质量，_无论您如何_ 使用基础模型：您可以使用循环、`if` 语句或异常进行编码，并在您认为适合您任务的任何 Python 控制流中使用 **DSPy** 模块。

假设您想要构建一个简单的检索增强生成（RAG）系统用于问答。您可以像这样定义自己的 `RAG` 程序：
```python
class RAG(dspy.Module):
    def __init__(self, num_passages=3):
        super().__init__()
        self.retrieve = dspy.Retrieve(k=num_passages)
        self.generate_answer = dspy.ChainOfThought("context, question -> answer")
    
    def forward(self, question):
        context = self.retrieve(question).passages
        answer = self.generate_answer(context=context, question=question)
        return answer
```
一个程序有两个关键方法，你可以编辑它们以满足你的需求。

**你的 `__init__` 方法** 声明了你将要使用的模块。在这里，`RAG` 将使用内置的 `Retrieve` 进行检索，使用 `ChainOfThought` 生成答案。**DSPy** 提供了通用模块，以满足_你自己_的子任务需求，而不是为特定应用程序预先构建的函数。

像 `ChainOfThought` 这样使用 LM 的模块需要一个_签名_。这是一个声明性规范，告诉模块它应该做什么。在这个例子中，我们使用了简写签名表示法 `context, question -> answer`，告诉 `ChainOfThought` 它将会得到一些 `context` 和一个 `question`，并且必须产生一个 `answer`。我们将在下面讨论更高级的 **[签名](#3a-declaring-the-inputoutput-behavior-of-lms-with-dspysignature)**。

**你的 `forward` 方法** 表达了你想要用你的模块进行的任何计算。在这种情况下，我们使用模块 `self.retrieve` 来搜索一些 `context`，然后使用模块 `self.generate_answer`，它使用 `context` 和 `question` 生成 `answer`！

现在你可以在**零-shot模式**下使用这个 `RAG` 程序。或者**编译**它以获得更高质量的结果。零-shot使用非常简单。只需定义程序的一个实例，然后调用它：

```python
rag = RAG()  # 零-shot，未编译版本的 RAG
rag("法国的首都是什么？").answer  # -> "巴黎"
```

下一节将讨论如何编译我们简单的 `RAG` 程序。当我们编译它时，**DSPy 编译器** 将注释其步骤的_演示_：(1) 检索，(2) 使用上下文，和 (3) 使用_思维链_来回答问题。从这些演示中，**DSPy 编译器** 将确保它生成一个有效的 few-shot 提示，可以很好地与你的 LM、检索模型和数据配合使用。如果你正在使用小型模型，它将微调你的模型（而不是提示）来执行此任务。

如果以后你决定在你的流程中添加另一个步骤，只需添加另一个模块，然后再次编译。也许添加一个在搜索过程中考虑聊天历史的模块？

## 4) 两个强大的概念：签名和提示器

**注意：** 我们很快将把提示器的名称更改为优化器。这不会影响其功能，但会简化所使用的术语。

为了使你编写的任何程序都能够编译，**DSPy** 引入了两个简单的概念：签名和提示器。

#### 4.a) 使用 `dspy.Signature` 声明 LM 的输入/输出行为

当我们在 **DSPy** 中为 LM 分配任务时，我们使用 **Signature** 指定我们需要的行为。签名是对 **DSPy 模块** 的输入/输出行为的声明规范。
与其努力投入到如何让您的 LM 完成一个子任务，签名使您能够告诉 **DSPy** 这个子任务是什么。稍后，**DSPy 编译器** 将会找出如何为您的大型 LM（或微调您的小型 LM）构建一个复杂的提示，特别针对您的签名、您的数据以及您的流水线。

签名由三个简单的元素组成：

- 对 LM 应该解决的子任务的最小描述。
- 一个或多个输入字段的描述（例如，输入问题），我们将提供给 LM。
- 一个或多个输出字段的描述（例如，问题的答案），我们期望从 LM 中得到。

我们支持两种表示签名的符号。**简写签名符号** 用于快速开发。您只需向您的模块（例如 `dspy.ChainOfThought`）提供一个字符串，其中包含 `input_field_name_1, ... -> output_field_name_1, ...`，字段之间用逗号分隔。

在之前的 `RAG` 类中，我们看到了：

```python
self.generate_answer = dspy.ChainOfThought("context, question -> answer")
```

在许多情况下，这种简单的签名就足够了。然而，有时您需要更多的控制。在这些情况下，我们可以使用完整的符号来表示更完整的签名，如下所示。

```python
class GenerateSearchQuery(dspy.Signature):
    """编写一个简单的搜索查询，以帮助回答一个复杂的问题。"""

    context = dspy.InputField(desc="可能包含相关事实")
    question = dspy.InputField()
    query = dspy.OutputField()

### 在程序的 __init__ 函数内
self.generate_answer = dspy.ChainOfThought(GenerateSearchQuery)
```

您可以选择为每个输入或输出字段提供 `prefix` 和/或 `desc` 键，以调整或约束使用您签名的模块的行为。子任务本身的描述被指定为文档字符串（即 `"""编写一个简单..."""`）。

#### 4.b) 要求 **DSPy** 使用 `dspy.teleprompt.*` 自动优化您的程序

在定义了 `RAG` 程序之后，我们可以对其进行**编译**。编译程序将更新存储在每个模块中的参数。对于大型 LM，这主要是创建和验证用于包含在您的提示中的良好演示的形式。

编译取决于三件事：一个（可能很小的）训练集，用于验证的度量标准，以及您从 **DSPy** 中选择的提示器。**提示器** 是强大的优化器（包含在 **DSPy** 中），它可以学习为任何程序的模块引导和选择有效的提示。 （名称中的 "tele-" 意味着 "在远处"，即自动远程提示。）
**DSPy** 通常只需要非常少的标记。例如，我们的 `RAG` 管道可能只需要包含一小部分示例，其中包含一个**问题**及其（人工注释的）**答案**。您的管道可能涉及多个复杂的步骤：我们基本的 `RAG` 示例包括一个检索到的上下文、一系列思路和答案。然而，您只需要为初始问题和最终答案标记。**DSPy** 将会为支持您的管道而需要的任何中间标签进行引导。如果您以任何方式更改了管道，那么引导的数据也会相应更改！

```python
my_rag_trainset = [
  dspy.Example(
    question="Gary Zukav的第一本书获得了哪个奖项？",
    answer="国家图书奖"
  ),
  ...
]
```

其次，定义您的验证逻辑，这将对程序或单个模块的行为施加一些约束。对于 `RAG`，我们可以表达一个简单的检查，如下所示：

```python
def validate_context_and_answer(example, pred, trace=None):
    # 检查黄金标签和预测答案是否相同
    answer_match = example.answer.lower() == pred.answer.lower()

    # 检查预测答案是否来自检索到的上下文之一
    context_match = any((pred.answer.lower() in c) for c in pred.context)

    return answer_match and context_match
```

不同的电子提示器在成本与质量等方面提供了各种权衡。对于 `RAG`，我们可以使用名为 `BootstrapFewShot` 的简单电子提示器。为此，我们使用验证函数 `my_rag_validation_logic` 实例化电子提示器本身，然后针对一些训练集 `my_rag_trainset` 进行编译。

```python
from dspy.teleprompt import BootstrapFewShot

teleprompter = BootstrapFewShot(metric=my_rag_validation_logic)
compiled_rag = teleprompter.compile(RAG(), trainset=my_rag_trainset)
```

如果我们现在使用 `compiled_rag`，它将在我们的数据上调用我们的 LM，使用富有启发性的提示和少量示范，进行思路链检索增强问答。

## 5) Pydantic 类型

有时您需要的不仅仅是字符串输入/输出。
例如，假设您需要查找

```python
from pydantic import BaseModel, Field
from dspy.functional import TypedPredictor

class TravelInformation(BaseModel):
    origin: str = Field(pattern=r"^[A-Z]{3}$")
    destination: str = Field(pattern=r"^[A-Z]{3}$")
    date: datetime.date
    confidence: float = Field(gt=0, lt=1)

class TravelSignature(Signature):
    """提取给定电子邮件中的所有旅行信息"""
    email: str = InputField()
    flight_information: list[TravelInformation] = OutputField()

predictor = TypedPredictor(TravelSignature)
predictor(email='...')
```

这将输出一个 `TravelInformation` 对象列表。

还有其他创建带类型签名的方法。比如
```python
predictor = TypedChainOfThought("question:str -> answer:int")
```
它应用思路链，并保证返回一个整数。
甚至还有一种受 [tanuki.py](https://github.com/Tanuki/tanuki.py) 启发的方法，当定义模块时可能会很方便：
```python
from dspy.functional import FunctionalModule, predictor, cot

class MyModule(FunctionalModule):
    @predictor
    def hard_question(possible_topics: list[str]) -> str:
        """基于其中一个主题提出一个难题。它应该可以通过一个数字来回答。"""

    @cot
    def answer(question: str) -> float:
        pass

    def forward(possible_topics: list[str]):
        q = hard_question(possible_topics=possible_topics)
        a = answer(question=q)
        return (q, a)
```

更多示例，请参见[上面的列表](https://github.com/stanfordnlp/dspy#:~:text=Typed%20DSPy)，以及该模块的[unit tests](https://github.com/stanfordnlp/dspy/blob/main/tests/functional/test_functional.py)。

## 6) 常见问题：DSPy 是否适合我？

**DSPy** 的理念和抽象与其他库和框架有很大不同，因此通常很容易确定在您的用例中 **DSPy** 是否是合适的框架。

如果您是自然语言处理（NLP）/人工智能（AI）研究人员（或者是探索新的流水线或新任务的从业者），答案通常是肯定的。如果您是从事其他工作的从业者，请继续阅读。

**[5.a] DSPy 与简单包装（OpenAI API、MiniChain、基本模板）相比**

换句话说：_为什么我不能直接将我的提示写成字符串模板？_ 嗯，在极其简单的情况下，这可能会很好地工作。（如果您熟悉神经网络，这就像将一个微小的两层神经网络表达为 Python for 循环。它确实可以工作。）

然而，当您需要更高质量（或可管理的成本）时，您需要迭代地探索多阶段分解、改进提示、数据引导、精细调整、检索增强，以及/或使用更小（或更便宜、本地）的模型。使用基础模型构建的真正表现力在于这些部分之间的交互。但每次更改一个部分时，您很可能会破坏（或削弱）多个其他组件。

**DSPy** 清晰地将这些与您实际系统设计无关的交互部分抽象出来（并且强大地优化）。它让您专注于设计模块级别的交互：在 **DSPy** 中表达的相同程序可以轻松编译成 `GPT-4` 的多阶段指令、`Llama2-13b` 的详细提示，或者 `T5-base` 的微调。

哦，而且您将不再需要在项目核心维护长而脆弱的特定于模型的字符串。



**[5.b] DSPy 与 LangChain、LlamaIndex 等应用开发库相比**


> _注：如果您将 LangChain 作为围绕自己提示字符串的简单包装使用，请参考答案 [5.a]。_
LangChain 和 LlamaIndex 是针对 LM 的高级应用开发的热门库。它们提供许多“一插即用”的预构建应用模块，可与您的数据或配置相连接。实际上，许多用例确实“不需要”任何特殊组件。如果您愿意使用别人为问答、PDF 或标准文本转 SQL 提供的通用现成提示，只要在您的数据上设置起来容易，那么您可能会在这些库中找到一个非常丰富的生态系统。

与这些库不同，**DSPy** 内部不包含专门针对特定应用程序的手工制作提示。相反，**DSPy** 引入了一组更强大、更通用的模块，可以在您的数据管道中学习提示（或微调）您的 LM。

**DSPy** 提供了完全不同程度的模块化：当您更改数据、对程序的控制流进行调整或更改目标 LM 时，**DSPy 编译器** 可以将您的程序映射到一组新的提示（或微调），这些提示专门针对这个管道进行了优化。由于这一点，您可能会发现 **DSPy** 在为您的任务获取最高质量时付出的努力最少，只要您愿意实现（或扩展）自己的简短程序。简而言之，**DSPy** 适用于需要轻量级但自动优化的编程模型，而不是预定义提示和集成的库。

如果您熟悉神经网络：
> 这就像 PyTorch（即代表 **DSPy**）与 HuggingFace Transformers（即代表更高级别的库）之间的区别。如果您只想使用现成的 `BERT-base-uncased` 或 `GPT2-large`，或对它们进行最小微调，HF Transformers 会使这变得非常简单。但是，如果您希望构建自己的架构（或显著扩展现有架构），您必须迅速转向像 PyTorch 这样更模块化的东西。幸运的是，HF Transformers 实际上是在 PyTorch 等后端中实现的。我们同样对围绕 **DSPy** 的高级封装程序为常见应用程序感到兴奋。如果使用 **DSPy** 实现这一点，您的高级应用程序也可以根据您的数据进行显著调整，这是静态提示链所无法做到的。如果您想帮助实现这一点，请[提交一个问题](https://github.com/stanfordnlp/dspy/issues/new)。

**[5.c] DSPy 与 Guidance、LMQL、RELM、Outlines 等生成控制库的比较**

Guidance、LMQL、RELM 和 Outlines 都是用于控制 LM 的个别完成的令人兴奋的新库，例如，如果您想强制执行 JSON 输出模式或将采样限制为特定正则表达式。
这在许多情境下都非常有用，但通常侧重于对单个语言模型调用的低级结构化控制。它并不能确保你得到的 JSON（或结构化输出）是正确的或对你的任务有用。

相比之下，**DSPy** 会自动优化程序中的提示，使其与各种任务需求对齐，这可能还包括生成有效的结构化输出。话虽如此，我们正在考虑允许 **DSPy** 中的 **Signatures** 表达类似正则表达式的约束，这些约束由这些库实现。


## 测试

要运行测试，你需要首先克隆存储库。

然后通过 poetry 安装包：
注意 - 你可能需要

```bash
poetry install --with test
```

然后使用以下命令运行所有测试，或特定的测试套件：

```bash
poetry run pytest
poetry run pytest tests/PATH_TO_TEST_SUITE
```

## 贡献快速入门

请参阅 [CONTRIBUTING.md](CONTRIBUTING.md) 以获取有关向 **DSPy** 贡献的快速入门指南。

## 贡献者和致谢

**DSPy** 由斯坦福大学 NLP 的 **Omar Khattab**、**Chris Potts** 和 **Matei Zaharia** 领导。

主要贡献者和团队成员包括 **Arnav Singhvi**、**Krista Opsahl-Ong**、**Michael Ryan**、**Cyrus Nouroozi**、**Kyle Caverly**、**Amir Mehr**、**Karel D'Oosterlinck**、**Shangyin Tan**、**Manish Shetty**、**Herumb Shandilya**、**Paridhi Maheshwari**、**Keshav Santhanam**、**Sri Vardhamanan**、**Eric Zhang**、**Hanna Moazam**、**Thomas Joshi**、**Saiful Haq** 和 **Ashutosh Sharma**。

**DSPy** 还得到了 **Rick Battle** 和 **Igor Kotenkov** 的重要贡献。它反映了与 **Peter Zhong**、**Haoze He**、**Lisa Li**、**David Hall**、**Ashwin Paranjape**、**Heather Miller**、**Chris Manning**、**Percy Liang** 等许多人的讨论。

**DSPy** 的标志由 **Chuyi Zhang** 设计。

## 📜 引用和了解更多

要保持最新或了解更多信息，请在 Twitter 上关注 [@lateinteraction](https://twitter.com/lateinteraction)。

如果你在研究论文中使用了 **DSPy** 或 **DSP**，请引用我们的工作如下：

```
@article{khattab2023dspy,
  title={DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and Miller, Heather and Zaharia, Matei and Potts, Christopher},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}
@article{khattab2022demonstrate,
  title={Demonstrate-Search-Predict: Composing Retrieval and Language Models for Knowledge-Intensive {NLP}},
  author={Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2212.14024},
  year={2022}
}
```

你也可以阅读更多关于从 Demonstrate-Search-Predict 框架到 **DSPy** 的演变的信息。
**DSPy断言：自我完善语言模型管道的计算约束**

- [**DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines**](https://arxiv.org/abs/2312.13382)（学术论文，2023年12月）
- [**DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines**](https://arxiv.org/abs/2310.03714)（学术论文，2023年10月）
- [**发布最新版本框架DSPy**](https://twitter.com/lateinteraction/status/1694748401374490946)（Twitter串，2023年8月）
- [**发布DSP编译器（v0.1）**](https://twitter.com/lateinteraction/status/1625231662849073160)（Twitter串，2023年2月）
- [**介绍DSP**](https://twitter.com/lateinteraction/status/1617953413576425472)（Twitter串，2023年1月）
- [**Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP**](https://arxiv.org/abs/2212.14024.pdf)（学术论文，2022年12月）

> _注：如果您正在寻找Demonstrate-Search-Predict（DSP），即DSPy的上一个版本，您可以在此存储库的[v1](https://github.com/stanfordnlp/dspy/tree/v1)分支中找到它。_